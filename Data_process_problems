问题 1. 怎么转换成 one-hot编码：
解决方法：有现成的函数  pd.get_dummies（数据集）函数

问题 2： 数据类型转换： 
解决方法：例如 image = image.astype(np.float64) 转化为float64    

问题 3： 当初要解决 如下问题： 一大串 有重复值的数据集， 要求统计种类， 并列出该种类 对应的index  [猪，牛，羊] 返回 index ：0， 1 ，2
解决方法：
        label = landmarks_frame['Type1']                       # <class 'pandas.core.series.Series'>
        # print('label:',  type(label), label)

        for j, m in enumerate(label[:]):
            if m in self.class_sample:
                pass
            else:
                self.class_sample.append(m)                    # 统计有多少种类
                # print('{} has add:', m)
        landmarks = self.class_sample.index(label_type)        # 取出种类对应的index
        

问题 4：此处新增加一个容易忽略的报错点： 比如你的 image 是 torch.Size([4, 3, 224, 224]) torch.float64 torch.DoubleTensor
       然后用 b = transforms.ToPILImage()(image[0]，就是取某一张 [3, 224, 224] ) 此时报错： TypeError: Input type float64 is not supported。
解决方法： image[0] 转化为 torch.float32 而不是 torch.float64

        
 
问题 5. 关于将数据集分为 train val test三部分 ，然而 没处理好def __len__（self）：函数， 导致数据集还是没分成 train val test三部分

如下：本想分为三部分  ，发现类实例化初始化后， 在调用实例对象时， 调用的len 里面没有将数据集分为三类，现在考虑将分三部分的放到 def __len__（self）：
里面（后来发现，根本不用这样做）
     def __init__(self, csv_file, root_dir, mode, transform=True):
        """
        :param csv_file (str): Path to the csv file with annotations
        :param root_dir(str): Directory with all the images
        :param transform: optional transform to be applied on a sample
        """
        print('1')
        self.landmarks_frame = pd.read_csv(csv_file)
        self.root_dir = root_dir
        # self.label_Onehot = label_Onehot
        self.transform = transform
        self.name2label = {}

        self.name = self.landmarks_frame['Name']
        self.label = self.landmarks_frame['Type1']
        self.class_sample = []
        print('len_name:', len(self.name))

        if mode == 'train':
            self.name = self.name[:int(0.8*len(self.name))]
            self.label = self.label[:int(0.8*len(self.label))]
            print('len_train:', len(self.name))
        elif mode == 'val':
            self.name = self.name[int(0.8*len(self.name)):int(0.9*len(self.name))]
            self.label = self.label[int(0.8*len(self.name)):int(0.9*len(self.name))]
            print('len_val:', len(self.name))
        else:
            self.name = self.name[int(0.9*len(self.name)):]
            self.label = self.label[int(0.9*len(self.name)):]
            print('len_test:', len(self.name))

    def __len__(self):
        return len(self.landmarks_frame)

    def __getitem__(self, idx):
        print('idx:', idx)
        if torch.is_tensor(idx):
            idx = idx.tolist()
            
   
   # 类初始化
   train_db = FaceLanmarksDataset(csv_file='/home/huangpan/Documents/pokemon_images/pokemon.csv',
                                            root_dir='/home/huangpan/Documents/pokemon_images/images/', mode='train',
                                            transform=transforms.Compose([Rescale(256), RandomCrop(224),
                                                                          ToTensor(), ]))
    val_db = FaceLanmarksDataset(csv_file='/home/huangpan/Documents/pokemon_images/pokemon.csv',
                                          root_dir='/home/huangpan/Documents/pokemon_images/images/', mode='val',
                                          transform=transforms.Compose([Rescale(256), RandomCrop(224),
                                                                        ToTensor(), ]))
    test_db = FaceLanmarksDataset(csv_file='/home/huangpan/Documents/pokemon_images/pokemon.csv',
                                           root_dir='/home/huangpan/Documents/pokemon_images/images/', mode='test',
                                           transform=transforms.Compose([Rescale(256), RandomCrop(224),
                                                                         ToTensor(), ]))
                                                                         
    # 实例对象调用len（）函数，获取的还是所有的长度，并没有将数据集分3部分
    train_loader = DataLoader(train_db, batch_size=4, shuffle=True, num_workers=0, drop_last=True)
    val_loader = DataLoader(val_db, batch_size=4,  num_workers=0, drop_last=True)
    test_loader = DataLoader(test_db, batch_size=4, num_workers=0, drop_last=True)

    print('len_train_data:', len(train_loader), 'len_val_data:', len(val_loader), 'len_test_data:', len(test_loader))  #  这里并没有分成3部分的长度
      
      
    方法： 修改成 如下即可。当调用len函数时， 会返回 3部分数据集对应的长度
        def __len__(self):
        return len(self.name)
         
